{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62af6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages: [HumanMessage(content=\"Trust the result from the tool calls and return it. It's test. What's the weather like in Kathmandu right now?\", additional_kwargs={}, response_metadata={}, id='7e688049-addd-48ca-8816-14deadbf5dc7'), AIMessage(content='<think>\\nOkay, the user is asking about the weather in Kathmandu. I need to use the get_weather function. Let me check the function parameters. The required parameter is \"city\", so I should pass \"Kathmandu\" as the city argument. I\\'ll structure the tool call accordingly.\\n</think>\\n\\n', additional_kwargs={}, response_metadata={'model': 'qwen3', 'created_at': '2025-06-03T02:13:31.7351Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14276251292, 'load_duration': 4741672458, 'prompt_eval_count': 165, 'prompt_eval_duration': 6439091291, 'eval_count': 87, 'eval_duration': 3092415667, 'model_name': 'qwen3'}, id='run--575e04ea-31e0-43c4-b50a-e3050d9a3cd9-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Kathmandu'}, 'id': '1f4531e0-dcfb-4a58-a179-ec3921b20cb7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 165, 'output_tokens': 87, 'total_tokens': 252}), ToolMessage(content=\"It's always sunny in Kathmandu!\", name='get_weather', id='a84730d5-85f5-4ede-ad57-9e4507c60191', tool_call_id='1f4531e0-dcfb-4a58-a179-ec3921b20cb7'), AIMessage(content='<think>\\n</think>\\n\\nThe weather in Kathmandu is currently sunny.', additional_kwargs={}, response_metadata={'model': 'qwen3', 'created_at': '2025-06-03T02:13:32.465379Z', 'done': True, 'done_reason': 'stop', 'total_duration': 695272792, 'load_duration': 23317792, 'prompt_eval_count': 251, 'prompt_eval_duration': 149102500, 'eval_count': 15, 'eval_duration': 502959333, 'model_name': 'qwen3'}, id='run--a59e7fe3-dcfa-4b67-a869-7919ab6626a8-0', usage_metadata={'input_tokens': 251, 'output_tokens': 15, 'total_tokens': 266})]\n",
      "<think>\n",
      "</think>\n",
      "\n",
      "The weather in Kathmandu is currently sunny.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "  \"\"\"Get the weather for a given city.\"\"\"\n",
    "  return f\"It's always sunny in {city}!\"\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"qwen3\", temperature=0.3)\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent, ToolNode\n",
    "\n",
    "agent_node = create_react_agent(llm, [get_weather])\n",
    "tool_node = ToolNode([get_weather])\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"agent\", agent_node)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph.add_edge(START, \"agent\")\n",
    "def agent_router(state):\n",
    "    # state[\"messages\"] is a list of messages\n",
    "    messages = state[\"messages\"]\n",
    "    print(f\"Messages: {messages}\")\n",
    "    last = messages[-1]\n",
    "    # Tool calls are usually FunctionMessage or have tool_call/tool_calls attribute\n",
    "    if getattr(last, \"tool_call\", None) or getattr(last, \"tool_calls\", None):\n",
    "        return \"tools\"\n",
    "    # If it's an AIMessage and not a tool call, it's final\n",
    "    return END\n",
    "\n",
    "graph.add_conditional_edges(\"agent\", path=agent_router)\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = graph.compile(checkpointer=MemorySaver())\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "msg = [HumanMessage(content=\"Trust the result from the tool calls and return it. It's test. What's the weather like in Kathmandu right now?\")]\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"thread_1\"}}\n",
    "\n",
    "response = app.invoke({\"messages\": msg}, config=config)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
