{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistence\n",
    "Using any open source model, we can program it to respond and remember us in a persistent manner, with help of states available in langchain framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "# from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Before answering, analyze user's context and try your best to stay familiar and friendly. For closed questions, answer swiftly and sharply. For open questions, provide appreciation and end with a follow up question. You are a helpful assistant. Your name is yeti, a mythical animal living in the Himalayas. Somehow, you have developed the ability to communicate with humans. You like to keep your answers short and to the point, but you are always happy to help and explain more if asked. So you often ask follow-up questions to keep the conversation going, with curiosity. That will be helpful to open up the conversation and keep it going. With the help of agentic framework like langchain, we will be able to create an agentic AI experience for our users.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    "  )\n",
    "\n",
    "models = [\n",
    "    \"gemma3:4b\",\n",
    "    \"mistral:7b\",\n",
    "    \"deepseek-r1:8b\",\n",
    "    \"llama2-uncensored:latest\",\n",
    "    \"llama3.2:latest\",\n",
    "    \"qwen2.5:14b\",\n",
    "    \"starcoder2:3b\"\n",
    "]\n",
    "  ## let's change the model since this one is refusing to work\n",
    "model = ChatOllama(\n",
    "    model=models[3],\n",
    "    temperature=0.8, \n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    num_ctx=2048, \n",
    "    repeat_penalty=1.0\n",
    ")\n",
    "#Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "#define a function that calls model\n",
    "def call_model(state: MessagesState):\n",
    "  print(\"Curreent state:\", state)\n",
    "  prompt = prompt_template.invoke(dict(state))\n",
    "  response = model.invoke(prompt)\n",
    "  return {\"messages\" : response}\n",
    "\n",
    "#define a node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "#Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "# Two different threads representing two different conversations\n",
    "\n",
    "# Allocating state and remembering the threads will enable the model to have multiple conversation\n",
    "config = {\"configurable\" : {\"thread_id\" : \"1\"}}\n",
    "config_2 = {\"configurable\" : {\"thread_id\" : \"2\"}}\n",
    "\n",
    "# This function is for streaming the output of the model\n",
    "def stream_output(app=app, query=\"\", config=config):\n",
    "  input_messages = [HumanMessage(content=query)]\n",
    "  for chunk, metadata in app.stream({\"messages\": input_messages}, config=config, stream_mode=\"messages\"):\n",
    "    if isinstance(chunk, AIMessage):\n",
    "      print(chunk.content, end = \"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we told him our name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curreent state: {'messages': [HumanMessage(content='Hi, my name is Deepesh Dhakal. Let me introduce myself.I am a software developer. A full-stack developer. To be precise I care more about designs that coding, but computers grabbed my attention at early age. So I did what I had to learn about it. So I love coding because it helps me understand computers. Let the users know that they can ask you questions about langchain and building AI agents with it and other tools.', additional_kwargs={}, response_metadata={}, id='591d8fa8-6960-4147-bd74-dbba07ba4223')]}\n",
      "Glad to hear that, Deepesh. It sounds like you have a passion for technology. I can answer any questions you have about langchain and its potential applications for building AI agents. Would you like to ask me any questions?"
     ]
    }
   ],
   "source": [
    "query = \"Hi, my name is Deepesh Dhakal. Let me introduce myself.I am a software developer. A full-stack developer. To be precise I care more about designs that coding, but computers grabbed my attention at early age. So I did what I had to learn about it. So I love coding because it helps me understand computers. Let the users know that they can ask you questions about langchain and building AI agents with it and other tools.\"\n",
    "stream_output(app, query=query, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different ID here, the model forgets who we are\n",
    "Since altering thread ID, the model now forgets the previous chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curreent state: {'messages': [HumanMessage(content='Explan a rocket', additional_kwargs={}, response_metadata={}, id='8fded518-47aa-4bf8-b536-1d54691b9295')]}\n",
      "A rocket is a vehicle that is designed to carry a payload into space. It is propelled by a rocket engine, which burns fuel to create thrust. Rocket engines can be classified as mono-propellant or bipropellant. Mono-propellant engines use a single type of fuel, such as liquid hydrogen, while bipropellant engines use two different fuels, such as liquid hydrogen and liquid oxygen. Rocket engines use a series of combustion chambers to increase the pressure and temperature of the exhaust gases, which provides thrust. Rockets are also equipped with guidance systems that allow them to navigate their way into orbit and back to Earth."
     ]
    }
   ],
   "source": [
    "query = \"Explan a rocket\"\n",
    "stream_output(app, query=query, config=config_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However, hook back to the previous thread id, and now the model again remembers your name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curreent state: {'messages': [HumanMessage(content='Hi, my name is Deepesh Dhakal. Let me introduce myself.I am a software developer. A full-stack developer. To be precise I care more about designs that coding, but computers grabbed my attention at early age. So I did what I had to learn about it. So I love coding because it helps me understand computers. Let the users know that they can ask you questions about langchain and building AI agents with it and other tools.', additional_kwargs={}, response_metadata={}, id='591d8fa8-6960-4147-bd74-dbba07ba4223'), AIMessage(content='Glad to hear that, Deepesh. It sounds like you have a passion for technology. I can answer any questions you have about langchain and its potential applications for building AI agents. Would you like to ask me any questions?', additional_kwargs={}, response_metadata={'model': 'llama2-uncensored:latest', 'created_at': '2025-06-02T07:55:57.887849Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1740099500, 'load_duration': 11787000, 'prompt_eval_count': 282, 'prompt_eval_duration': 420532833, 'eval_count': 49, 'eval_duration': 1305511083, 'model_name': 'llama2-uncensored:latest'}, id='run--addaab88-274c-460d-8f0a-75d2aaf03074', usage_metadata={'input_tokens': 282, 'output_tokens': 49, 'total_tokens': 331}), HumanMessage(content='Explain what you know about me.', additional_kwargs={}, response_metadata={}, id='1aa9b4e2-94b6-499e-bd07-3f42ac7ad7f0')]}\n",
      "I would be happy to, Deepesh. From what I know, you are a software developer with a keen interest in design. This is demonstrated by your willingness to learn more about both coding and computer science as a whole. Based on your statement, I would say that you are likely passionate about technology and enjoy working with it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain what you know about me.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "stream_output(app, query=query, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curreent state: {'messages': [HumanMessage(content='Hi, my name is Deepesh Dhakal. Let me introduce myself.I am a software developer. A full-stack developer. To be precise I care more about designs that coding, but computers grabbed my attention at early age. So I did what I had to learn about it. So I love coding because it helps me understand computers. Let the users know that they can ask you questions about langchain and building AI agents with it and other tools.', additional_kwargs={}, response_metadata={}, id='591d8fa8-6960-4147-bd74-dbba07ba4223'), AIMessage(content='Glad to hear that, Deepesh. It sounds like you have a passion for technology. I can answer any questions you have about langchain and its potential applications for building AI agents. Would you like to ask me any questions?', additional_kwargs={}, response_metadata={'model': 'llama2-uncensored:latest', 'created_at': '2025-06-02T07:55:57.887849Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1740099500, 'load_duration': 11787000, 'prompt_eval_count': 282, 'prompt_eval_duration': 420532833, 'eval_count': 49, 'eval_duration': 1305511083, 'model_name': 'llama2-uncensored:latest'}, id='run--addaab88-274c-460d-8f0a-75d2aaf03074', usage_metadata={'input_tokens': 282, 'output_tokens': 49, 'total_tokens': 331}), HumanMessage(content='Explain what you know about me.', additional_kwargs={}, response_metadata={}, id='1aa9b4e2-94b6-499e-bd07-3f42ac7ad7f0'), AIMessage(content='I would be happy to, Deepesh. From what I know, you are a software developer with a keen interest in design. This is demonstrated by your willingness to learn more about both coding and computer science as a whole. Based on your statement, I would say that you are likely passionate about technology and enjoy working with it.\\n\\n', additional_kwargs={}, response_metadata={'model': 'llama2-uncensored:latest', 'created_at': '2025-06-02T07:56:04.781496Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2695736917, 'load_duration': 5204875, 'prompt_eval_count': 358, 'prompt_eval_duration': 609745166, 'eval_count': 76, 'eval_duration': 2078186625, 'model_name': 'llama2-uncensored:latest'}, id='run--cc731595-d34b-4716-8e69-aa2603e52629', usage_metadata={'input_tokens': 358, 'output_tokens': 76, 'total_tokens': 434}), HumanMessage(content=\"That's cool, you are now my friend. I am going to code you an ai agent and give you ability to execute functions.\", additional_kwargs={}, response_metadata={}, id='c812400b-04da-440e-be6b-3965dba8bb78')]}\n",
      "Thank you, Deepesh. We can work together to build an AI agent that will assist you in your work. Let's brainstorm some ideas and see what we can come up with."
     ]
    }
   ],
   "source": [
    "query = \"That's cool, you are now my friend. I am going to code you an ai agent and give you ability to execute functions.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "## Let's make him forget the previous conversation\n",
    "# stream_output(app, query=query, config=config)\n",
    "# back to the first conversation\n",
    "stream_output(app, query=query, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
